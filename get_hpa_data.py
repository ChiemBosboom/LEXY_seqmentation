# -*- coding: utf-8 -*-
"""Get_HPA_Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zF3QyvYMmQlBtqSgtLCMDHwP4NT7IcJf
"""

working_dir = ''

!pip install cellpose

# Commented out IPython magic to ensure Python compatibility.
# Torch and torchvision imports
import torch
from torch import nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import torchvision
from torchvision import datasets, transforms
from torchvision.transforms import ToTensor

# Scikit-image and scipy imports
from skimage import io, filters, measure, morphology, segmentation, color, feature
from skimage.filters import threshold_li, gaussian
from skimage.feature import peak_local_max
from skimage.morphology import remove_small_objects
from skimage.segmentation import watershed
from skimage.transform import resize
from scipy.ndimage import distance_transform_edt
from scipy import ndimage as ndi

# Other imports
import numpy as np
import matplotlib
matplotlib.rcParams["image.interpolation"] = 'none'
import matplotlib.pyplot as plt
# %matplotlib inline
# %config InlineBackend.figure_format = 'retina'
from PIL import Image
import cv2
import random
from lxml import etree
import requests
from tqdm.auto import tqdm
import os
import albumentations as A
import re
from cellpose import models, core

# Scikit-learn imports
from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, f1_score

# Device agnostic
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Define the URL of the XML file
url = 'https://www.proteinatlas.org/search/subcell_location%3ACytosol%2CNucleoplasm+NOT+subcell_location%3AActin+filaments%2CAggresome%2CCell+Junctions%2CCentriolar+satellite%2CCentrosome%2CCleavage+furrow%2CCytokinetic+bridge%2CCytoplasmic+bodies%2CEndoplasmic+reticulum%2CEndosomes%2CFocal+adhesion+sites%2CGolgi+apparatus%2CIntermediate+filaments%2CKinetochore%2CLipid+droplets%2CLysosomes%2CMicrotubule+ends%2CMicrotubules%2CMidbody%2CMidbody+ring%2CMitochondria%2CMitotic+chromosome%2CMitotic+spindle%2CNuclear+bodies%2CNuclear+membrane%2CNuclear+speckles%2CNucleoli%2CNucleoli+fibrillar+center%2CNucleoli+rim%2CPeroxisomes%2CPlasma+membrane%2CRods+%26+Rings%2CVesicles?format=xml&download=yes'
path = os.path.join(working_dir, 'subcell_location_Cytosol_Nucleoplasm_only.xml')

# Download the file using wget
os.system(f'wget -O "{path}" "{url}"')

def iterate_xml(xmlfile):
    doc = etree.iterparse(xmlfile, events=('start', 'end'))
    _, root = next(doc)
    start_tag = "imageUrl"
    for event, element in doc:
        if event == 'start' and start_tag is None:
            start_tag = element.tag
        if event == 'end' and element.tag == start_tag:
            yield element
            start_tag = "imageUrl"
            root.clear()

urls = []
for i in iterate_xml(path):
    #print(i.text)
    if "blue_red_green" in i.text:
        urls.append(i.text)

# Create three new lists by replacing 'blue_red_green' with 'blue' and 'green' and 'yellow'
blue_urls = [url.replace('blue_red_green', 'blue') for url in urls]
green_urls = [url.replace('blue_red_green', 'green') for url in urls]

# Print the filtered URLs
print(f'Found {len(urls)} image URLS')

# Function to download and save an image
def download_image(url, save_dir):
    try:
        session = requests.Session()
        response = session.get(url, allow_redirects=False)

        # Manually handle redirect to HTTPS
        if response.status_code in (301, 302):
            new_url = response.headers.get('Location')
            if new_url and new_url.startswith("https://"):
                response = session.get(new_url, allow_redirects=True)
                response.raise_for_status()  # Check if the request was successful
            else:
                print(f"Unexpected redirect location for {url}: {new_url}")
                return

        response.raise_for_status()  # Check if the request was successful

        # Extract the image name from the original URL
        image_name = url.split("/")[-1]

        # Create the full path to save the image
        save_path = os.path.join(save_dir, image_name)

        # Write the image content to a file
        with open(save_path, "wb") as file:
            file.write(response.content)

    except requests.RequestException as e:
        print(f"Failed to download {url}: {e}")

# Define directories and URLs
categories = {
    'blue': blue_urls,
    'green': green_urls,
}

# Create directories and download images
for category, urls in categories.items():
    category_dir = os.path.join(working_dir, category)
    os.makedirs(category_dir, exist_ok=True)

    print(f"Downloading {category} images...")
    for url in tqdm(urls, desc=f"{category}"):
        download_image(url, category_dir)

# init model
use_GPU = core.use_gpu()
print('>>> GPU activated? %d'%use_GPU)

model = models.Cellpose(gpu=use_GPU, model_type='nuclei')

# load in DAPI images
image_dir = os.path.join(working_dir, 'blue')
blue_names = sorted(os.listdir(image_dir))

nuclei = []

for blue_name in tqdm(blue_names):

    nuc_path = os.path.join(image_dir, blue_name)
    nucleus = io.imread(nuc_path, as_gray=True)
    nucleus = resize(nucleus, (256, 256), anti_aliasing=False)
    nuclei.append(nucleus)

# Get masks from DAPI images
def batch_process_images(images, batch_size):
    processed_images = []
    total_batches = len(images) // batch_size + (1 if len(images) % batch_size != 0 else 0)

    for i in tqdm(range(total_batches)):
        start_idx = i * batch_size
        end_idx = min((i + 1) * batch_size, len(images))
        batch = images[start_idx:end_idx]
        masks, flows, styles, diams = model.eval(batch, diameter=None, flow_threshold=None, channels=[0,0])
        processed_images.extend(masks)

    return processed_images

batch_size = 32
masks = batch_process_images(nuclei, batch_size)

# save directories
green_dir = os.path.join(working_dir, 'green')
blue_dir = os.path.join(working_dir, 'blue')

#splitting data
green_names = os.listdir(green_dir)
blue_names = sorted(os.listdir(blue_dir))

# Generate a list of indices
indices = list(range(len(blue_names)))

# Shuffle the indices
random.shuffle(indices)

# Apply the shuffled indices to both lists
shuffled_blue_names = [blue_names[i] for i in indices]
shuffled_masks = [masks[i] for i in indices]

# Calculate split indices
total_size = len(blue_names)
train_size = int(0.8 * total_size)
val_size = int(0.1 * total_size)
test_size = total_size - train_size - val_size

# Split the data
train_data = shuffled_blue_names[:train_size]
val_data = shuffled_blue_names[train_size:train_size + val_size]
test_data = shuffled_blue_names[train_size + val_size:]

train_masks = shuffled_masks[:train_size]
val_masks = shuffled_masks[train_size:train_size + val_size]
test_masks = shuffled_masks[train_size + val_size:]

def segment_and_extract_nuclei(image_path, mask, min_area=100, density=8):
    # Load and resize the image
    image = io.imread(image_path, as_gray=True)
    image = resize(image, (256, 256), anti_aliasing=True)

    # Remove small objects from mask
    mask = remove_small_objects(mask.astype(bool), min_size=min_area).astype(np.float32)

    # Measure properties
    regions = measure.regionprops(mask)

    # Filter regions to not include edge touching nuclei
    image_height, image_width = image.shape

    valid_regions = [
        region for region in regions
        if (region.bbox[0] > 0 and region.bbox[1] > 0 and
            region.bbox[2] < image_height and region.bbox[3] < image_width)
    ]

    half_size = 64  # Half of the desired sub-image size (128x128)
    image_stack = []

    if len(valid_regions) <= density:
        for region in valid_regions:
            center_r, center_c = map(int, region.centroid)

            # Calculate start and end indices, ensuring they fit within image bounds
            start_r = max(center_r - half_size, 0)
            end_r = min(center_r + half_size, image.shape[0])
            start_c = max(center_c - half_size, 0)
            end_c = min(center_c + half_size, image.shape[1])

            # Adjust the region to be exactly 128x128 if it's at the edge
            if end_r - start_r < 128:
                if start_r == 0:
                    end_r = min(128, image.shape[0])
                else:
                    start_r = max(image.shape[0] - 128, 0)
            if end_c - start_c < 128:
                if start_c == 0:
                    end_c = min(128, image.shape[1])
                else:
                    start_c = max(image.shape[1] - 128, 0)

            # Extract sub-image and corresponding mask
            sub_image = image[start_r:end_r, start_c:end_c]
            sub_nuc = mask[start_r:end_r, start_c:end_c]
            binary_mask = sub_nuc > 0

            # remove small segmentations on the edge
            binary_mask = remove_small_objects(binary_mask.astype(bool), min_size=min_area).astype(np.float32)

            # Normalize sub-image
            sub_image = sub_image / np.max(sub_image)
            sub_image = sub_image.astype(np.float32)

            # Stack and add to list
            image_stack.append(np.stack((sub_image, binary_mask), axis=0))

    return image_stack

# Function to process images
def process_images(data, masks):
    images_list = []
    for i, blue_name in enumerate(tqdm(data)):
        try:
            # Add green images
            green_name = blue_name.replace('blue', 'green')
            sub_images = segment_and_extract_nuclei(os.path.join(green_dir, green_name),
                                                    masks[i])
            images_list.extend(sub_images)

        except Exception as e:
            print(f"Error: {e} for {blue_name}, skipping...")
            continue

    return images_list

# Process each dataset
images_train = process_images(train_data, train_masks)
images_val = process_images(val_data, val_masks)
images_test = process_images(test_data, test_masks)

np.savez(os.path.join(working_dir, 'images_train.npz'), *images_train)
np.savez(os.path.join(working_dir, 'images_val.npz'), *images_val)
np.savez(os.path.join(working_dir, 'images_test.npz'), *images_test)

# visualize
n_examples = 5

fig = plt.figure(figsize=(12, 12))
rows, cols = n_examples, 3
random = np.random.randint(0, len(images_train), n_examples)
n = 1

for i in range(n_examples):

    cell, segment = images_train[random[i]]

    fig.add_subplot(rows, cols, n)
    plt.imshow(cell.squeeze(), cmap='gray')
    plt.axis(False)

    fig.add_subplot(rows, cols, n + 1)
    plt.imshow(segment.squeeze(), cmap='gray')
    plt.axis(False)

    fig.add_subplot(rows, cols, n + 2)
    plt.imshow(segment, cmap='gray')
    plt.imshow(cell, cmap='jet', alpha=0.5)
    plt.axis(False)

    n += 3

"""Make synthetic HPA sequence"""

# Load the arrays from .npz file
images_test = np.load(os.path.join(working_dir, 'images_test.npz'))
images_val = np.load(os.path.join(working_dir, 'images_val.npz'))

# Convert the loaded arrays back into a list
images_val = [images_val[f'arr_{i}'] for i in range(len(images_val.files))]
images_test = [images_test[f'arr_{i}'] for i in range(len(images_test.files))]

def touches_border(mask):
    # Check if any part of the mask touches the border of the image
    return np.any(mask[1, 0, :] == 1) or \
           np.any(mask[1, -1, :] == 1) or \
           np.any(mask[1, :, 0] == 1) or \
           np.any(mask[1, :, -1] == 1)

filtered_val = [arr for arr in images_val if not touches_border(arr)]
filtered_test = [arr for arr in images_test if not touches_border(arr)]

def filter_images(data, intensity_difference_threshold=0.1):

    filtered = []

    for img, mask in data:
        # Step 1: Apply Otsu's thresholding
        otsu_threshold = threshold_otsu(img)
        otsu_mask = img > otsu_threshold

        # Step 2: Create cytoplasm mask by dilating the original mask and excluding the original mask area
        cyto_mask = morphology.binary_dilation(mask, footprint=np.ones((9, 9)))
        cyto_mask = cyto_mask & ~mask.astype(bool) & otsu_mask

        # Step 3: Calculate the intensity difference
        int_dif = np.mean(img[cyto_mask]) - np.mean(img[mask.astype(bool)])

        # Step 4: Filter based on the intensity difference threshold
        if abs(int_dif) < intensity_difference_threshold:
            filtered.append((img, mask))

    return filtered

filtered_val = filter_images(filtered_val)
filtered_test = filter_images(filtered_test)

def apply_transformation(frame, mask, translation):
    # Define transformation parameters
    shear = translation * 0.05
    stretch = translation * 0.05
    rotation_angle = translation * 0.05

    # Construct the affine transformation matrices
    transform = AffineTransform(shear=shear, scale=(1 + stretch, 1 + stretch))

    # Apply affine transformation (shearing + stretching) and rotation
    frame_transformed = warp(frame, transform.inverse, order=0, mode='constant', cval=0)
    mask_transformed = warp(mask, transform.inverse, order=0, mode='constant', cval=0)

    # Apply the rotation without interpolation
    frame_transformed = rotate(frame_transformed, angle=rotation_angle, reshape=False, order=0, mode='constant', cval=0)
    mask_transformed = rotate(mask_transformed, angle=rotation_angle, reshape=False, order=0, mode='constant', cval=0)

    # Smooth mask_transformed
    smoothed_mask = gaussian(mask_transformed, sigma=1.5)
    binary_smoothed_mask = (smoothed_mask > 0.5).astype(np.float32)

    return frame_transformed, binary_smoothed_mask

def create_seq(array, max_translation = 2):
    # Extract the frame and mask
    img = array[0]
    mask = array[1]

    # Initialize lists to store frames and masks
    frames = []
    masks = []

    # Generate sequence of images with intensity changes based on mask
    for i in np.linspace(4.0, 1.0, num=8):
        img_new = np.copy(img)
        img_new[mask.astype(bool)] *= i
        frames.append(img_new)
        masks.append(np.copy(mask))

    for i in np.linspace(1.0, 4.0, num=8):
        if i == 1.0:
            continue
        img_new = np.copy(img)
        img_new[mask.astype(bool)] /=  i
        frames.append(img_new)
        masks.append(np.copy(mask))

    frames.extend(frames[::-1])
    masks.extend(masks[::-1])

    # Apply the transformation progressively
    transformed_frames = []
    transformed_masks = []

    sequence_length = len(frames)

    for i in range(sequence_length):
        #transform images sequentially
        interpolation_factor = (2 * i / (sequence_length - 1)) - 1
        translation = interpolation_factor * max_translation
        transformed_frame, transformed_mask = apply_transformation(frames[i], masks[i], translation)

        # Blur edges
        edges = canny(transformed_mask.astype(np.float32))
        edges = morphology.binary_dilation(edges)
        transformed_frame[edges] = gaussian(transformed_frame[edges], sigma=0.7)

        # Normalize
        transformed_frame = transformed_frame / np.max(transformed_frame)

        # append frames
        transformed_frames.append(transformed_frame.astype(np.float32))
        transformed_masks.append(transformed_mask)

    # add masks to frames
    image_sequence = []
    for i in range(len(transformed_frames)):
        image_sequence.append(np.stack([transformed_frames[i], transformed_masks[i]], axis=0))

    return np.stack(image_sequence)

img_seq_val = [create_seq(img) for img in filtered_val]
img_seq_test = [create_seq(img) for img in filtered_test]

np.savez(os.path.join(working_dir, 'img_seq_val.npz'), *img_seq_val)
np.savez(os.path.join(working_dir, 'img_seq_test.npz'), *img_seq_test)