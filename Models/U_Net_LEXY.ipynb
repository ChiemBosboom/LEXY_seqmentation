{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChiemBosboom/LEXY_seqmentation/blob/main/Models/U_Net_LEXY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LEXY_file_path = ''  # path to LEXY tifs\n",
        "working_dir = ''  # path to working directory"
      ],
      "metadata": {
        "id": "wA1KiMUHjYBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch and torchvision imports\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Scikit-image, scipy, Scikit-learn imports\n",
        "from skimage import io, filters, measure, morphology, segmentation, color, feature\n",
        "from skimage.filters import threshold_li, gaussian, threshold_otsu\n",
        "from skimage.feature import peak_local_max, canny\n",
        "from skimage.morphology import remove_small_objects\n",
        "from skimage.transform import resize, AffineTransform, warp\n",
        "from skimage.metrics import hausdorff_distance\n",
        "from scipy.ndimage import distance_transform_edt, rotate\n",
        "from scipy import ndimage as ndi\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, f1_score\n",
        "\n",
        "# miscellaneous imports\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import albumentations as A\n",
        "import re\n",
        "\n",
        "# Device agnostic\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "cDnMxRShJXT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unet model\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv_op = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv_op(x)\n",
        "\n",
        "\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        down = self.conv(x)\n",
        "        p = self.pool(down)\n",
        "\n",
        "        return down, p\n",
        "\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(\n",
        "            in_channels, in_channels // 2, kernel_size=2, stride=2\n",
        "        )\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x = torch.cat([x1, x2], 1)\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "5T5ZyBqeKJcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classic UNet\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.down_convolution_1 = DownSample(1, 64)\n",
        "        self.down_convolution_2 = DownSample(64, 128)\n",
        "        self.down_convolution_3 = DownSample(128, 256)\n",
        "        self.down_convolution_4 = DownSample(256, 512)\n",
        "\n",
        "        self.bottle_neck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up_convolution_1 = UpSample(1024, 512)\n",
        "        self.up_convolution_2 = UpSample(512, 256)\n",
        "        self.up_convolution_3 = UpSample(256, 128)\n",
        "        self.up_convolution_4 = UpSample(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_1, p1 = self.down_convolution_1(x)\n",
        "        down_2, p2 = self.down_convolution_2(p1)\n",
        "        down_3, p3 = self.down_convolution_3(p2)\n",
        "        down_4, p4 = self.down_convolution_4(p3)\n",
        "\n",
        "        b = self.bottle_neck(p4)\n",
        "\n",
        "        up_1 = self.up_convolution_1(b, down_4)\n",
        "        up_2 = self.up_convolution_2(up_1, down_3)\n",
        "        up_3 = self.up_convolution_3(up_2, down_2)\n",
        "        up_4 = self.up_convolution_4(up_3, down_1)\n",
        "\n",
        "        out = self.out(up_4)\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# UNet based on VGG16 encoder\n",
        "class VGG16_UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        vgg16 = torchvision.models.vgg16(weights='DEFAULT')\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Modify the first convolutional layer to accept 1 channel instead of 3\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
        "            *vgg16.features[1:]\n",
        "        )\n",
        "        # Initialize weights from pretrained VGG16 model\n",
        "        self.encoder[0].weight.data = vgg16.features[0].weight.mean(dim=1, keepdim=True)\n",
        "        self.encoder[0].bias.data = vgg16.features[0].bias.data\n",
        "\n",
        "        # Define convolutional blocks corresponding to VGG layers\n",
        "        self.conv_1 = nn.Sequential(*self.encoder[:4])\n",
        "        self.conv_2 = nn.Sequential(*self.encoder[5:9])\n",
        "        self.conv_3 = nn.Sequential(*self.encoder[10:16])\n",
        "        self.conv_4 = nn.Sequential(*self.encoder[17:23])\n",
        "        self.conv_5 = nn.Sequential(*self.encoder[24:30])\n",
        "\n",
        "        self.bottle_neck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up_convolution_1 = UpSample(512 + 512, 1024)\n",
        "        self.up_convolution_2 = UpSample(512 + 512, 512)\n",
        "        self.up_convolution_3 = UpSample(256 + 256, 256)\n",
        "        self.up_convolution_4 = UpSample(128 + 128, 128)\n",
        "        self.up_convolution_5 = UpSample(64 + 64, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_1 = self.conv_1(x)                      # 1 > 64\n",
        "        down_2 = self.conv_2(self.pool(down_1))      # 64 > 128\n",
        "        down_3 = self.conv_3(self.pool(down_2))      # 128 > 256\n",
        "        down_4 = self.conv_4(self.pool(down_3))      # 256 > 512\n",
        "        down_5 = self.conv_5(self.pool(down_4))      # 512 > 512\n",
        "\n",
        "        b = self.bottle_neck(self.pool(down_5))\n",
        "\n",
        "        up_1 = self.up_convolution_1(b, down_5)\n",
        "        up_2 = self.up_convolution_2(up_1, down_4)\n",
        "        up_3 = self.up_convolution_3(up_2, down_3)\n",
        "        up_4 = self.up_convolution_4(up_3, down_2)\n",
        "        up_5 = self.up_convolution_5(up_4, down_1)\n",
        "\n",
        "        out = self.out(up_5)\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# UNet based on ResNet34 encoder\n",
        "class ResNet34_UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        resnet = torchvision.models.resnet34(weights='DEFAULT')\n",
        "        self.pool = resnet.maxpool\n",
        "\n",
        "        # Modify the first convolutional layer to accept 1 channel instead of 3\n",
        "        self.layer0 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            resnet.bn1,\n",
        "            resnet.relu\n",
        "        )\n",
        "        # Initialize weights from pretrained ResNet34 model\n",
        "        self.layer0[0].weight.data = resnet.conv1.weight.mean(dim=1, keepdim=True)\n",
        "\n",
        "        self.layer1 = resnet.layer1\n",
        "        self.layer2 = resnet.layer2\n",
        "        self.layer3 = resnet.layer3\n",
        "        self.layer4 = resnet.layer4\n",
        "\n",
        "        self.bottle_neck = DoubleConv(512, 1024)\n",
        "\n",
        "        self.up_convolution_1 = UpSample(1024, 512)\n",
        "        self.up_convolution_2 = UpSample(512, 256)\n",
        "        self.up_convolution_3 = UpSample(256, 128)\n",
        "        self.up_convolution_4 = UpSample(128, 64)\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        down_0 = self.layer0(x)                      # 1 > 64\n",
        "        down_1 = self.layer1(down_0)                 # 64 > 64\n",
        "        down_2 = self.layer2(down_1)                 # 64 > 128\n",
        "        down_3 = self.layer3(down_2)                 # 128 > 256\n",
        "        down_4 = self.layer4(down_3)                 # 256 > 512\n",
        "\n",
        "        b = self.bottle_neck(self.pool(down_4))\n",
        "\n",
        "        up_1 = self.up_convolution_1(b, down_4)\n",
        "        up_2 = self.up_convolution_2(up_1, down_3)\n",
        "        up_3 = self.up_convolution_3(up_2, down_2)\n",
        "        up_4 = self.up_convolution_4(up_3, down_1)\n",
        "\n",
        "        out = self.out(up_4)\n",
        "        out = torch.sigmoid(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "yT65KFkmPY4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True, loss_type='combined'):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "        self.loss_type = loss_type  # Initialize with a default loss_type\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1, loss_type=None):\n",
        "        \"\"\"\n",
        "        loss_type can be 'combined', 'dice', or 'bce' to specify which loss is returned first.\n",
        "        If not provided, it will default to the loss_type set during initialization.\n",
        "        \"\"\"\n",
        "        # If loss_type is provided during the forward pass, use it; otherwise, use the initialized loss_type\n",
        "        if loss_type is None:\n",
        "            loss_type = self.loss_type\n",
        "\n",
        "        # Flatten label and prediction tensors\n",
        "        inputs = inputs.reshape(-1)\n",
        "        targets = targets.reshape(-1)\n",
        "\n",
        "        # Dice loss\n",
        "        intersection = (inputs * targets).sum()\n",
        "        dice_loss = 1 - (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
        "\n",
        "        # Calculate weights\n",
        "        weights = torch.where(targets == 1, 2.0, 1.0)\n",
        "\n",
        "        # BCE loss\n",
        "        BCE = F.binary_cross_entropy(inputs, targets, weight=weights, reduction='mean')\n",
        "\n",
        "        # Combine Dice loss and BCE loss\n",
        "        Dice_BCE = BCE + dice_loss\n",
        "\n",
        "        # Return the losses\n",
        "        if loss_type == 'combined':\n",
        "            return Dice_BCE, dice_loss, BCE\n",
        "        elif loss_type == 'dice':\n",
        "            return dice_loss, dice_loss, BCE\n",
        "        elif loss_type == 'bce':\n",
        "            return BCE, dice_loss, BCE\n",
        "        else:\n",
        "            raise ValueError(\"loss_type must be 'combined', 'dice', or 'bce'\")"
      ],
      "metadata": {
        "id": "V6AGJ2COh45Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, loss_fn, optimizer):\n",
        "    # Initialize cumulative loss values\n",
        "    train_loss = 0\n",
        "    train_dice_loss = 0\n",
        "    train_BCE = 0\n",
        "\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    for img in train_loader:\n",
        "        # Extract input image (X) and target mask (y)\n",
        "        X = img[:, 0, :, :].unsqueeze(1)\n",
        "        y = img[:, 1, :, :]\n",
        "\n",
        "        # Forward pass: Predict output mask using the model\n",
        "        y_pred = model(X).squeeze()\n",
        "\n",
        "        # Calculate the losses\n",
        "        loss, dice_loss, BCE = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "        train_dice_loss += dice_loss.item()\n",
        "        train_BCE += BCE.item()\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate average losses over the entire training set\n",
        "    train_loss /= len(train_loader)\n",
        "    train_dice_loss /= len(train_loader)\n",
        "    train_BCE /= len(train_loader)\n",
        "\n",
        "    return train_loss, train_dice_loss, train_BCE\n",
        "\n",
        "def test_model(model, test_loader, loss_fn):\n",
        "    # Initialize cumulative loss values\n",
        "    test_loss = 0\n",
        "    test_dice_loss = 0\n",
        "    test_BCE = 0\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img in test_loader:\n",
        "            # Extract input image (X_test) and target mask (y_test)\n",
        "            X_test = img[:, 0, :, :].unsqueeze(1)\n",
        "            y_test = img[:, 1, :, :]\n",
        "\n",
        "            # Forward pass: Predict output mask using the model\n",
        "            test_pred = model(X_test).squeeze()\n",
        "\n",
        "            # Calculate the losses\n",
        "            loss, dice_loss, BCE = loss_fn(test_pred, y_test)\n",
        "            test_loss += loss.item()\n",
        "            test_dice_loss += dice_loss.item()\n",
        "            test_BCE += BCE.item()\n",
        "\n",
        "    # Calculate average losses over the entire test set\n",
        "    test_loss /= len(test_loader)\n",
        "    test_dice_loss /= len(test_loader)\n",
        "    test_BCE /= len(test_loader)\n",
        "\n",
        "    return test_loss, test_dice_loss, test_BCE\n",
        "\n",
        "def fit_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=5):\n",
        "    test_loss_list = []\n",
        "    train_loss_list = []\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        print(f'Epoch {epoch + 1}/{epochs}')\n",
        "\n",
        "        # Train the model and get training losses\n",
        "        train_loss, dice_train, BCE_train = train_model(model, train_loader, loss_fn, optimizer)\n",
        "        train_loss_list.append(round(train_loss, 4))\n",
        "\n",
        "        # Evaluate the model on the test set and get test losses\n",
        "        test_loss, dice_test, BCE_test = test_model(model, test_loader, loss_fn)\n",
        "        test_loss_list.append(round(test_loss, 4))\n",
        "\n",
        "        # Print the training and test losses for this epoch\n",
        "        print(f'Training Loss: {train_loss:.4f} (DICE: {dice_train:.4f}, BCE: {BCE_train:.4f}) | Test Loss: {test_loss:.4f} (DICE: {dice_test:.4f}, BCE: {BCE_test:.4f})')\n",
        "\n",
        "    return train_loss_list, test_loss_list\n",
        "\n",
        "def plot_loss(train_loss_list, test_loss_list):\n",
        "    # Plot the training and test loss curves over epochs\n",
        "    epochs = range(1, len(train_loss_list) + 1)\n",
        "\n",
        "    plt.plot(epochs, train_loss_list, 'b', label='Training Loss')\n",
        "    plt.plot(epochs, test_loss_list, 'r', label='test Loss')\n",
        "    plt.title('Training and test Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Initialize lists to store per-sample metrics\n",
        "    sensitivity_list, specificity_list, dice_list, hd_list = [], [], [], []\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img in data_loader:\n",
        "            # Extract input image (X_test) and target mask (y_test)\n",
        "            X_test = img[:, 0, :, :].unsqueeze(1)\n",
        "            y_test = img[:, 1, :, :].to(torch.int)\n",
        "\n",
        "            # Forward pass: Predict output mask using the model\n",
        "            test_pred = model(X_test).squeeze()\n",
        "\n",
        "            # Binarize the predictions based on a threshold (0.5)\n",
        "            test_pred = (test_pred >= 0.5).to(torch.int)\n",
        "\n",
        "            # Move to numpy for processing\n",
        "            test_pred_np = test_pred.cpu().numpy()\n",
        "            y_test_np = y_test.cpu().numpy()\n",
        "            predictions.append(test_pred_np)\n",
        "\n",
        "            for i in range(X_test.shape[0]):\n",
        "                # Get the boundary pixels using the Canny edge detector\n",
        "                edges_y = canny(y_test_np[i].astype(bool))\n",
        "                edges_pred = canny(test_pred_np[i].astype(bool))\n",
        "\n",
        "                # Compute the Hausdorff distance in both directions\n",
        "                d1 = hausdorff_distance(edges_y, edges_pred)\n",
        "                d2 = hausdorff_distance(edges_pred, edges_y)\n",
        "                hd_list.append(max(d1, d2))\n",
        "\n",
        "                # Flatten the predictions and targets for evaluation\n",
        "                test_pred_flat = test_pred_np[i].flatten()\n",
        "                y_test_flat = y_test_np[i].flatten()\n",
        "\n",
        "                # Compute confusion matrix components\n",
        "                tn, fp, fn, tp = confusion_matrix(y_test_flat, test_pred_flat, labels=[0, 1]).ravel()\n",
        "\n",
        "                # Calculate and store metrics for this batch\n",
        "                sensitivity_list.append(recall_score(y_test_flat, test_pred_flat))\n",
        "                specificity_list.append(tn / (tn + fp) if (tn + fp) != 0 else 0)\n",
        "                dice_list.append(f1_score(y_test_flat, test_pred_flat))\n",
        "\n",
        "    # ignore any inf in hd\n",
        "    hd_array = np.array(hd_list)[np.isfinite(hd_list)]\n",
        "\n",
        "    # Calculate mean and standard deviation for each metric\n",
        "    avg_sensitivity = np.mean(sensitivity_list)\n",
        "    std_sensitivity = np.std(sensitivity_list)\n",
        "\n",
        "    avg_specificity = np.mean(specificity_list)\n",
        "    std_specificity = np.std(specificity_list)\n",
        "\n",
        "    avg_dice_coefficient = np.mean(dice_list)\n",
        "    std_dice_coefficient = np.std(dice_list)\n",
        "\n",
        "    avg_hausdorff_distance = np.mean(hd_array)\n",
        "    std_hausdorff_distance = np.std(hd_array)\n",
        "\n",
        "    return [[avg_sensitivity, std_sensitivity],\n",
        "            [avg_specificity, std_specificity],\n",
        "            [avg_dice_coefficient, std_dice_coefficient],\n",
        "            [avg_hausdorff_distance, std_hausdorff_distance]], predictions"
      ],
      "metadata": {
        "id": "FTyBSmhiK3ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformations for data augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(size=(512, 512)),\n",
        "    transforms.Resize((128, 128), interpolation=Image.NEAREST),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=random.choice([(0, 0), (90, 90), (180, 180), (270, 270)])),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.CenterCrop(size=(512, 512)),\n",
        "    transforms.Resize((128, 128), interpolation=Image.NEAREST),\n",
        "])\n",
        "\n",
        "class LEXY(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "\n",
        "        # Convert numpy arrays to tensors\n",
        "        self.data = [torch.tensor(d, dtype=torch.float32).to(device) for d in data]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Extract image and mask from the tensor\n",
        "        sample = self.data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "U3Rw18ffr9M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_number(s):\n",
        "    match = re.search(r'[a-zA-Z](\\d{1,2})', s)\n",
        "    return int(match.group(1)) if match else float('inf')\n",
        "\n",
        "def load_images(file_path):\n",
        "    filenames = sorted(next(os.walk(file_path), (None, None, []))[2], key=extract_number)\n",
        "    images_dict = {}\n",
        "\n",
        "    for fname in filenames:\n",
        "        image = io.imread(os.path.join(file_path, fname))\n",
        "        cell_id = fname.split('_')[4]\n",
        "        if cell_id not in images_dict:\n",
        "            images_dict[cell_id] = []\n",
        "        images_dict[cell_id].append(image.astype(np.float32))\n",
        "\n",
        "    return images_dict\n",
        "\n",
        "def process_images(images):\n",
        "    for i in range(len(images)):\n",
        "        if images[i][1, 0, 0] == 255:\n",
        "            images[i] = np.stack((images[i][0, :, :], 255 - images[i][1, :, :]), axis=0)\n",
        "\n",
        "        if (images[i][1, 0, 0] == 0) & (images[i][1, 1, 1] == 255):\n",
        "            images[i] = np.stack((images[i][0, :, :], 255 - images[i][1, :, :]), axis=0)\n",
        "\n",
        "            images[i][1, :, 0] = 0\n",
        "            images[i][1, 0, :] = 0\n",
        "            images[i][1, :, images[i].shape[2] - 1] = 0\n",
        "            images[i][1, images[i].shape[1] - 1, :] = 0\n",
        "\n",
        "    return images\n",
        "\n",
        "def min_max_normalize(image):\n",
        "    # Find the minimum and maximum pixel values in the image\n",
        "    min_val = np.min(image)\n",
        "    max_val = np.max(image)\n",
        "\n",
        "    # Apply the Min-Max normalization\n",
        "    normalized_image = (image - min_val) / (max_val - min_val)\n",
        "\n",
        "    return normalized_image\n",
        "\n",
        "def adjust_background_mean(images, desired_mean=0.01):\n",
        "\n",
        "    adjusted_images = []\n",
        "    for img in images:\n",
        "\n",
        "        # extract cell and mask image\n",
        "        cell = img[0]\n",
        "        mask = img[1]\n",
        "\n",
        "        # get background mask\n",
        "        bg_mask = cell < threshold_li(cell)\n",
        "\n",
        "        # normalize images\n",
        "        cell = min_max_normalize(cell)\n",
        "        mask = mask / 255.0\n",
        "\n",
        "        # Calculate the current mean of the background\n",
        "        current_mean = np.mean(cell[bg_mask])\n",
        "\n",
        "        # Compute the shift required to reach the desired mean\n",
        "        shift = desired_mean / current_mean\n",
        "\n",
        "        # Apply the shift to the background pixels\n",
        "        adjusted_image = cell * shift\n",
        "\n",
        "        # add adjusted cell to mask\n",
        "        adjusted_image = np.stack((adjusted_image, mask), axis=0)\n",
        "        adjusted_images.append(adjusted_image)\n",
        "\n",
        "    return adjusted_images"
      ],
      "metadata": {
        "id": "3dA-yKP6cuhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the images\n",
        "images_dict = load_images(LEXY_file_path)\n",
        "\n",
        "# Set up cross-validation\n",
        "cell_ids = sorted(images_dict.keys())\n",
        "results = {cell_id: [] for cell_id in cell_ids}\n",
        "\n",
        "for cell in tqdm(cell_ids, desc=\"preprocessing images\"):\n",
        "    # Process each dataset\n",
        "    images = process_images(images_dict[cell])\n",
        "    images = adjust_background_mean(images)\n",
        "    images_dict[cell] = images\n",
        "\n",
        "for test_cell in tqdm(cell_ids, desc=\"cross validation\"):\n",
        "    images_train = []\n",
        "    images_test = images_dict[test_cell]\n",
        "\n",
        "    for train_cell in cell_ids:\n",
        "        if train_cell != test_cell:\n",
        "            images_train.extend(images_dict[train_cell])\n",
        "\n",
        "    # Use LEXY dataset with transformations\n",
        "    train_dataset = LEXY(data=images_train, transform=train_transforms)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "    test_dataset = LEXY(data=images_test, transform=test_transforms)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # model initialization\n",
        "    loss_type = '' # loss_type must be 'combined', 'dice', or 'bce'\n",
        "    loss_fn = DiceBCELoss(loss_type=loss_type)\n",
        "    model = UNet().to(device)  # model_name must be 'UNet', 'VGG16_UNet', or 'ResNet34_UNet'\n",
        "    pretrained_path = ''  # optional path to pretrained model state_dict\n",
        "\n",
        "    if pretrained_path != '':\n",
        "        pretrained = True\n",
        "        model.load_state_dict(torch.load(pretrained_path))\n",
        "    else:\n",
        "        pretrained = False\n",
        "\n",
        "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
        "\n",
        "    # train model\n",
        "    train_loss_list, test_loss_list = fit_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=10)\n",
        "    plot_loss(train_loss_list, test_loss_list)\n",
        "\n",
        "    # test model\n",
        "    metrics, predictions = evaluate_model(model, test_loader)\n",
        "    metrics.extend([train_loss_list, test_loss_list, predictions])\n",
        "    results[test_cell] = metrics"
      ],
      "metadata": {
        "id": "jPtPvQAyh0TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot results\n",
        "cell_id = 'C10'\n",
        "\n",
        "predictions = results[cell_id][6][0]\n",
        "cell_images = images_dict[cell_id]\n",
        "num_images = len(predictions)\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(nrows=num_images, ncols=3, figsize=(15, 5 * num_images))\n",
        "\n",
        "for i in range(num_images):\n",
        "    cell_image = cell_images[i][0]  # Extract cell image\n",
        "    ground_truth = cell_images[i][1]  # Extract ground truth\n",
        "\n",
        "    # Plot cell image\n",
        "    axes[i, 0].imshow(cell_image, cmap='gray')\n",
        "    axes[i, 0].set_title(f'Cell Image {i+1}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Plot ground truth\n",
        "    axes[i, 1].imshow(ground_truth, cmap='gray')\n",
        "    axes[i, 1].set_title(f'Ground Truth {i+1}')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    # Plot prediction\n",
        "    axes[i, 2].imshow(predictions[i], cmap='gray')\n",
        "    axes[i, 2].set_title(f'Prediction {i+1}')\n",
        "    axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cvtRzx3INsQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save results\n",
        "results_file = os.path.join(working_dir, f\"{'pretrained_' if pretrained else ''}LEXY_results_{model.__class__.__name__}_{loss_type}.txt\")\n",
        "model_file = os.path.join(working_dir, f\"{'pretrained_' if pretrained else ''}LEXY_model_{model.__class__.__name__}_{loss_type}.pth\")\n",
        "\n",
        "with open(results_file, 'w') as file:\n",
        "    for cell in results:\n",
        "        stats = results[cell]\n",
        "        file.write(f'results for cell {cell}:\\n'\n",
        "                   f'sensitivity: {stats[0]}\\n'\n",
        "                   f'specificity: {stats[1]}\\n'\n",
        "                   f'dice coefficient: {stats[2]}\\n'\n",
        "                   f'hausdorff distance: {stats[3]}\\n'\n",
        "                   f'train loss: {stats[4]}\\n'\n",
        "                   f'test loss: {stats[5]}\\n\\n')\n",
        "\n",
        "torch.save(model.state_dict(), model_file)"
      ],
      "metadata": {
        "id": "iLjqYAw0IzZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize accumulators for the means\n",
        "total_dice_coefficient = 0\n",
        "total_hausdorff_distance = 0\n",
        "\n",
        "num_cells = len(results)\n",
        "\n",
        "# Calculate sums for mean calculations\n",
        "for cell in results:\n",
        "    stats = results[cell]\n",
        "    total_dice_coefficient += stats[2][0]\n",
        "    total_hausdorff_distance += stats[3][0]\n",
        "\n",
        "# Calculate the means outside of the file-writing process\n",
        "mean_dice_coefficient = total_dice_coefficient / num_cells\n",
        "mean_hausdorff_distance = total_hausdorff_distance / num_cells\n",
        "\n",
        "# Print the means\n",
        "print(f\"Mean Dice Coefficient: {mean_dice_coefficient}\")\n",
        "print(f\"Mean Hausdorff Distance: {mean_hausdorff_distance}\")"
      ],
      "metadata": {
        "id": "cbTTWU5leegb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}